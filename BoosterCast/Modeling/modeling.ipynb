{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4825d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_price(data):\n",
    "    \"\"\"\n",
    "    Cleans and converts the 'price' field from a string to a float.\n",
    "    Handles cases with missing values, commas, and unexpected formats.\n",
    "\n",
    "    :param data: Dictionary containing the 'price' field as a string.\n",
    "    :return: Updated dictionary with 'price' as a float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        price_str = str(data.get(\"price\", \"\")).strip()\n",
    "        if not price_str:\n",
    "            raise ValueError(\"Empty price value\")\n",
    "\n",
    "        price_match = re.search(r\"[\\d,]+(\\.\\d{1,2})?\", price_str)\n",
    "        if not price_match:\n",
    "            raise ValueError(f\"Invalid price format: {price_str}\")\n",
    "\n",
    "        clean_price = float(price_match.group().replace(\",\", \"\"))\n",
    "        data[\"price\"] = clean_price\n",
    "    except (ValueError, TypeError) as e:\n",
    "        print(f\"Warning: {e}. Setting price to None.\")\n",
    "        data[\"price\"] = None \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_condition(data):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes the 'condition' field by extracting key condition labels\n",
    "    and identifying special flags such as '4 Pack Minimum' and 'KOREAN'.\n",
    "\n",
    "    :param data: Dictionary containing the 'condition' field as a string\n",
    "    :return: Updated dictionary with standardized 'condition' and extracted flags\n",
    "    \"\"\"\n",
    "    condition_text = data.get(\"condition\", \"\").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    condition_keywords = [\"Unopened\", \"Sealed\", \"Opened\", \"New\", \"Used\"]\n",
    "\n",
    "    primary_condition = None\n",
    "    for keyword in condition_keywords:\n",
    "        if keyword.lower() in condition_text.lower():\n",
    "            primary_condition = keyword\n",
    "            break\n",
    "\n",
    "    data[\"condition\"] = primary_condition if primary_condition else \"Unknown\"\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7cf7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def clean_quantity(data, apply_log=False):\n",
    "    \"\"\"\n",
    "    Converts the 'quantity' field to an integer.\n",
    "    If conversion fails, sets the quantity to 0.\n",
    "    Optionally applies a log transform to the value.\n",
    "\n",
    "    :param data: Dictionary containing the 'quantity' field.\n",
    "    :param apply_log: Boolean to indicate whether to apply a logarithm transform.\n",
    "    :return: The updated dictionary with cleaned 'quantity'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        quantity = int(str(data.get(\"quantity\", \"\")).strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: {e}. Setting quantity to 0.\")\n",
    "        quantity = 0\n",
    "\n",
    "    if apply_log and quantity > 0:\n",
    "        quantity = round(math.log(quantity), 4)\n",
    "\n",
    "    data[\"quantity\"] = quantity\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def clean_date(data):\n",
    "    \"\"\"\n",
    "    Converts the 'date' field from a string like \"2/15/25\" to a datetime object.\n",
    "    Also extracts additional features such as day_of_year and month.\n",
    "    \n",
    "    :param data: Dictionary containing the 'date' field.\n",
    "    :return: Updated dictionary with 'date' as a datetime object and extra date features.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_str = data.get(\"date\", \"\").strip()\n",
    "        if not date_str:\n",
    "            raise ValueError(\"Empty date string\")\n",
    "        \n",
    "        dt = datetime.strptime(date_str, \"%m/%d/%y\")\n",
    "        data[\"date\"] = dt\n",
    "        \n",
    "        data[\"day_of_year\"] = dt.timetuple().tm_yday\n",
    "        data[\"month\"] = dt.month\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: {e}. Date conversion failed for: {data.get('date')}\")\n",
    "        data[\"date\"] = None\n",
    "        data[\"day_of_year\"] = None\n",
    "        data[\"month\"] = None\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f947d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning_process(market_history):\n",
    "    for item in market_history:\n",
    "        clean_price(item)\n",
    "        clean_condition(item)\n",
    "        clean_quantity(item)\n",
    "        clean_date(item)\n",
    "    return market_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aee4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load and prepare data\n",
    "def read_json_file(filepath):\n",
    "    \"\"\"Read JSON data from file\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "A = read_json_file('scraped_results.json')\n",
    "B = read_json_file('scraped_results2.json')\n",
    "\n",
    "for item in B:\n",
    "    A.append(item)\n",
    "for item in A:\n",
    "    cleaning_process(item)\n",
    "\n",
    "flattened_data = []\n",
    "for item_index, item_data in enumerate(A):\n",
    "    for record in item_data:\n",
    "        record[\"item_id\"] = item_index\n",
    "        flattened_data.append(record)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df['item_id'] = df['item_id'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4984e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    \"\"\"Add temporal features to the dataset.\"\"\"\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    \n",
    "    # Fourier terms for seasonality\n",
    "    df['weekly_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['weekly_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['yearly_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['yearly_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_lag_features(df):\n",
    "    \"\"\"Add lagged price features.\"\"\"\n",
    "    df['price_lag_1'] = df.groupby('item_id')['price'].shift(1)\n",
    "    df['price_lag_2'] = df.groupby('item_id')['price'].shift(2)\n",
    "    df['price_lag_7'] = df.groupby('item_id')['price'].shift(7)\n",
    "    return df\n",
    "\n",
    "def add_differenced_features(df):\n",
    "    \"\"\"Add features that capture price changes.\"\"\"\n",
    "    df['price_diff_1'] = df.groupby('item_id')['price'].diff(1)  # Daily change\n",
    "    df['price_diff_7'] = df.groupby('item_id')['price'].diff(7)   # Weekly change\n",
    "    df['price_pct_change_1'] = df.groupby('item_id')['price'].pct_change(1)\n",
    "    return df\n",
    "\n",
    "def add_rolling_features(df):\n",
    "    \"\"\"Add rolling statistics.\"\"\"\n",
    "    windows = [3, 7, 14, 30]  # Multiple window sizes\n",
    "    for window in windows:\n",
    "        df[f'rolling_avg_{window}'] = df.groupby('item_id')['price'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'rolling_std_{window}'] = df.groupby('item_id')['price'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def add_mean_reversion_features(df):\n",
    "    \"\"\"Add features that capture deviation from typical levels.\"\"\"\n",
    "    # Deviation from rolling averages\n",
    "    df['deviation_from_7day'] = df['price'] - df['rolling_avg_7']\n",
    "    df['deviation_from_30day'] = df['price'] - df['rolling_avg_30']\n",
    "    \n",
    "    # Z-score of current price\n",
    "    df['price_zscore'] = df.groupby('item_id')['price'].transform(\n",
    "        lambda x: (x - x.rolling(window=30, min_periods=1).mean()) / \n",
    "                 x.rolling(window=30, min_periods=1).std()\n",
    "    )\n",
    "    \n",
    "    # Price position within recent range\n",
    "    df['price_percentile_30'] = df.groupby('item_id')['price'].transform(\n",
    "        lambda x: x.rolling(window=30, min_periods=1).apply(\n",
    "            lambda y: np.sum(y < y.iloc[-1]) / len(y) if len(y) > 1 else 0.5\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply all feature engineering\n",
    "df = add_temporal_features(df)\n",
    "df = add_lag_features(df)\n",
    "df = add_differenced_features(df)\n",
    "df = add_rolling_features(df)\n",
    "df = add_mean_reversion_features(df)\n",
    "\n",
    "# Drop rows with missing values (from lag features)\n",
    "df = df.dropna()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
